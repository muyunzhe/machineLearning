https://zhuanlan.zhihu.com/p/27657264
使用vgg16作为预训练的模型结构，并把它应用到手写数字识别上。

## 场景一：数据集小，数据相似度高(与pre-trained model的训练数据相比而言)
在这种情况下，因为数据与预训练模型的训练数据相似度很高，因此我们不需要重新训练模型。我们只需要将输出层改制成符合问题情境下的结构就好。

我们使用预处理模型作为模式提取器。

比如说我们使用在ImageNet上训练的模型来辨认一组新照片中的小猫小狗。在这里，需要被辨认的图片与ImageNet库中的图片类似，但是我们的输出结果中只需要两项——猫或者狗。

在这个例子中，我们需要做的就是把dense layer和最终softmax layer的输出从1000个类别改为2个类别。

## 场景二：数据集小，数据相似度不高

在这种情况下，我们可以冻结预训练模型中的前k个层中的权重，然后重新训练后面的n-k个层，当然最后一层也需要根据相应的输出格式来进行修改。

因为数据的相似度不高，重新训练的过程就变得非常关键。而新数据集大小的不足，则是通过冻结预训练模型的前k层进行弥补。

## 场景三：数据集大，数据相似度不高

在这种情况下，因为我们有一个很大的数据集，所以神经网络的训练过程将会比较有效率。然而，因为实际数据与预训练模型的训练数据之间存在很大差异，采用预训练模型将不会是一种高效的方式。

因此最好的方法还是将预处理模型中的权重全都初始化后在新数据集的基础上重头开始训练。

## 场景四：数据集大，数据相似度高

这就是最理想的情况，采用预训练模型会变得非常高效。最好的运用方式是保持模型原有的结构和初始权重不变，随后在新数据集的基础上重新训练。